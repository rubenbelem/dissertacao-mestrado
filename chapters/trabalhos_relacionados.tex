\section{Trabalhos relacionados}\label{sec:referencias}
\label{sec:related_work}

O problema de CATE foi primeiramente estudado por \cite{chaudhuri2009extending} e \cite{ji2009efficient}. Ambos propuseram soluções baseadas em computar de forma incremental um conjunto de nós ativos de uma Trie, a qual funciona como índice para a base de consultas que poderão ser sugeridas. A ideia geral comum entre os dois algoritmos é a de que os algoritmos calculam um conjunto de ``nós ativos'' que correspondem a todos os prefixos encontrados na Trie similares a cada letra nova de um prefixo de consulta $p$ digitado pelo usuário, dentro de um limite de distância de edição $\tau$. A partir desses prefixos calculados, é possível recuperar o restante do texto das consultas que serão sugeridas na própria árvore.

Chaudhuri et al. \cite{chaudhuri2009extending} apresentam um método de complementação automática de consultas que leva em consideração erros de digitação no prefixo. Antes disso, para cenários em que havia uma tabela de frases para pesquisar, a forma mais comum de preenchimento automático era a comparação exata de caracteres. Dois algoritmos de complementação automática tolerantes à falha de digitação foram propostos \citep{chaudhuri2009extending}. O primeiro é baseado nos algoritmos de distância de edição em q-gramas\citep{arasu2006efficient, chaudhuri2006primitive, xiao2008ed}. O segundo é um algoritmo baseado em \textit{trie}, que mantém um conjunto de \textit{nós ativos} de forma incremental para processar as complementações. O método utiliza distância de edição clássica como medida de similaridade entre cadeias de caracteres. Esse algoritmo é muito similar ao proposto por \cite{ji2009efficient}, porém, realiza uma etapa a mais, que consiste em pré-computar o conjunto de nós ativos para todas as possíveis consultas com até certo tamanho. Uma vez que o número de nós ativos pode ser muito grande ao realizar complementação de consultas tolerante a erros, essa estratégia ajuda a reduzir o tempo de processamento das consultas.

% A indicação da complementação automática exata contribui para guiar o usuário durante a digitação, poupando significativas quantidades de cliques e, em certa medida, reduz a probabilidade de erros serem cometidos. Entretanto, se o usuário digita um caractere errado, a complementação automática exata já não traria o resultado desejado, o que é uma ocorrência bastante comum em digitações rápidas e nas relações entre fonética e o modo de escrita ortográfica.

Para abordar o problema de CATE , Ji et. al \citep{ji2009efficient} propõem um algoritmo chamado \textit{ICAN} que computa nós ativos de forma incremental, ou seja, processa o prefixo consultado caractere a caractere, como mencionado anteriormente. Nosso método proposto na seção~\ref{sec:metodo} utiliza uma otimização desse algortimo, o ICPAN \citep{li2011efficient}. Portanto, ambos serão descritos com mais detalhes a seguir. 

Seja $p$ um prefixo consultado e $\tau$ um limite de distância de edição. Um nó $n$ da \textit{trie} é chamado \textit{nó ativo de p em relação à $\tau$} quando a distância de edição entre a cadeia de caracteres de $p$ e à cadeia de $n$ estiver dentro do limite $\tau$, ou em outras palavras, $ed(n, p) \leq \tau$. Os nós-folha da subárvore com raiz em $n$ são denominados ``palavras similares à $p$'' \citep{ji2009efficient}. 

Considerando uma consulta de prefixo $p$ com apenas uma palavra-chave, para processar os nós ativos de forma eficiente é necessário computar e armazenar um conjunto de tuplas $\Phi_{p} = \{ \langle n, \xi_{n} \rangle \}$ tal que (1) cada $n$ é um nó ativo em relação à $p$ com $\xi_{n} = ed(n, p) \leq \tau)$ e (2) quaisquer nós ativos de $p$ estão presentes em $\Phi_{p}$, que é o \textit{conjunto de nós ativos de p} \citep{ji2009efficient}. Quando o usuário digita mais um caractere $p + 1$ após ter digitado $p$, o conjunto $\Phi_{p}$ de nós ativos de $p$ pode ser usado para computar o conjunto $\Phi_{p + 1}$ de nós ativos da nova consulta.

Uma desvantagem do algoritmo ICAN é que pode ser bastante custoso manter o conjunto de nós ativos para grandes quantidades de dados. Para atenuar esse problema, Li et al. \citep{li2011efficient} desenvolveram um método otimizado denominado \textit{ICPAN}, que realiza a poda de nós ativos desnecessários durante o processamento de consultas enquanto continua conseguindo computar todos os itens similares ao prefixo consultado. Isso permite a redução do espaço necessário para armazenar os nós ativos computados e também melhora a performance da busca, uma vez que não é necessário verificar todos os nós ativos para a computação incremental.

O ICPAN define um subconjunto dos nós ativos que pode ser usado para computar todas as palavras similares à consulta de forma eficiente e incremental. Para isso, Li et al. \citep{li2011efficient} estabelecem a seguinte observação: dado um nó ativo $n$ de $p$, se para qualquer transformação de $n$ para $p$ com $ed(n,p)$ operações de edição, não houver uma operação de correspondência (caracteres iguais) no último caractere de $n$, e for possível deletar o último caractere de $n$, o nó $n$ não é mantido, e sim o seu nó pai. Assim, surge o conceito de \textit{nó pivô ativo}.

Considerando prefixo de consulta $p$, um nó da \textit{trie} $n$ é um nó pivô ativo de $p$ em relação à $\tau$ se, e somente se (1) $n$ é um nó ativo de $p$ e (2) se existe uma transformação de $p$ para $n$ com $ed(n,p)$ operações, e a operação no último caractere de $n$ é uma correspondência. Em outras palavras, a operação nesse caractere de $n$ não é nem uma deleção $ed(n,p) \neq ed(n',p) + 1$ e nem uma substituição $ed(n,p) \neq ed(n', p') + 1$, onde $n'$ e $p'$ são respectivamente os prefixos de $n$ e $p$ que não contêm o último caractere.

Dada uma consulta de prefixo $p_{x}$, de forma análoga ao ICAN, é preciso computar e armazenar um conjunto de tuplas $\Psi_{p_{x}} = \{ \langle n, \xi_{n}^{p_{x}}, m_{i}, \xi_{n}^{p_{i}} \rangle \}$ \citep{li2011efficient}. Em cada tupla, $n$ é um nó pivô ativo de $p_{x}$. O elemento $m_{i}$ é um prefixo de $p_{x}$ tal que os últimos caracteres de $n$ e $m_{i}$ são iguais. Se não existir tal prefixo, então $m_{i} = \epsilon$ (cadeia de caracteres vazia). Se existirem múltiplos prefixos com essa condição, somente aquele com o menor comprimento é selecionado. $\xi_{n}^{p_{i}} \leq \tau$ é uma distância de transformação entre o nó $n$ para $m_{i}$ com uma operação de correspondência entre seus últimos caracteres. $\xi_{n}^{p_{x}} \leq \tau$ é a distância de transformação entre o nó $n$ para $p_{x}$ obtida ao primeiro transformar o nó $n$ para $m_{i}$ e então inserir os caracteres após $m_{i}$. O ICPAN é um algoritmo que computa $\Psi{p_{x}}$ e garante que cada nó pivô ativo de $p_{x}$ aparece como o $n$ em uma tupla de $\Psi{p_{x}}$.

\textbf{ REFAZER OS COMENTÁRIOS SOBRE INCNGTRIE. NÃO ESTAO CLAROS, NÃO ESTÃO FAZENDO SENTIDO. TENTA EXPLICAR A DIFERENCA ENTRE ELE E OS ANTERIORES USANDO TUAS PALAVRAS}

% Xiao et al. \citep{xiao2013efficient} desenvolveram um algoritmo baseado em geração de vizinhança, o ``IncNGTrie''. Esse algoritmo proposto mantém apenas um pequeno conjunto de nós ativos, reduzindo o tempo de processamento da consulta. Esse método, também baseado em \textit{trie}, reduz de forma eficiente as duplicações nas respostas, até então um problema central nas respostas de buscas. O trabalho resolve o problema de CATE com as restrições de distância de edição através de exclusão de variantes marcadas. 

A avaliação experimental realizada pelo estudo em conjuntos de dados reais em larga escala demonstra que o IncNGTrie supera as soluções (até então) existentes em até duas ordens de grandeza em termos de tempo de resposta da consulta. No entanto, há dois principais efeitos colaterais dessa proposta de solução: (1) o tempo de indexação aumenta, uma vez que é preciso calcular todas as variantes marcadas de cada consulta (quanto maior o valor de $\tau$, maior a quantidade de variantes), e (2) o imenso aumento da quantidade de memória necessária para manter o índice gerado. 

Zhou et al. \citep{zhou2016beva} propõem uma estrutura geral que engloba métodos da complementação automática existentes, o ``BEVA'', caracterizando diferentes classes de algoritmos e a quantidade mínima de informações que eles precisam manter para diversas restrições. É proposta também uma nova estratégia de armazenamento de nós ativos, eliminando inteiramente os relacionamentos entre nós pais e filhos. O framework realiza computação de distância de edição por uma nova estrutura de dados chamada ``\textit{edit vector automaton}'' (EVA), permitindo calcular novos nós ativos e seus estados associados de forma eficiente através de pesquisas de tabela. O modelo é capaz de suportar limiares de grande distância através de um autômato. Os estudos do trabalho indicam que o método supera as abordagens até então existentes, tanto em tempo quanto na eficiência do espaço.

Deng et al. \citep{deng2016meta} desenvolveram um método denominado ``META'', uma estrutura baseada em correspondências que calcula as respostas com base em caracteres correspondentes entre os dados das consultas e os dados indexados. A estrutura desenvolvida é capaz de reduzir cálculos redundantes, organizando-os através de índices de árvore compacta. Para processar as respostas às consultas foi proposto um método incremental que responde eficientemente consultas \textit{top-k}. Através dos experimentos realizados no estudo, percebe-se que, apesar dos métodos até então considerados estado-da-arte não realizarem respostas eficientes para consultas \textit{top-k}, o método META supera estas abordagens.

Todos os trabalhos supracitados utilizam Trie como seu principal índice para realizar a computação de prefixos similares ao prefixo de consulta digitado pelo usuário. Isso fornece uma forte base empírica para considerar que essa estrutura de dados realmente é vantajosa para o problema de CATE em se tratando do tempo de processamento. No entanto, as árvores Trie tendem a consumir uma alta quantidade de memória quando a base de consultas indexada é muito grande e não há muitos prefixos em comum entre os itens. Uma das formas de contornar esse problema é utilizar uma estratégia de indexação e busca em dois níveis.

Manber et al. \citep{manber1994glimpse} apresentam o ``GLIMPSE'' (\textit{GLobal IMPlicit Search}) ou ``Busca Implícita Global'', uma ferramenta que possibilita a realização de consultas para sistemas de arquivos com baixa indexação, onde apenas 2\% e 4\% do tamanho do texto é indexado. O GLIMPSE apresentou uma abordagem até então nova para a indexação e realização de consultas de arquivos, denominada de ``busca em dois níveis''.

A ideia da busca em dois níveis aplicada no GLIMPSE consiste em combinar índices invertidos completos com busca sequencial sem indexação. Essa abordagem se baseia na observação de que a busca sequencial é rápida o suficiente para textos de vários \textit{megabytes} de tamanho, e que por isso não é necessário indexar todas as palavras do documento com suas localizações exatas. Na busca em dois níveis, o índice não fornece os locais exatos das palavras, mas apenas uma indicação da região onde a resposta possa ser encontrada, funcionando como uma espécia de ``filtro''. Essa abordagem no entanto, apesar de economizar bastante espaço de indexação a velocidade de busca, se mostrou inferior aos modelos que utilizam apenas indexadores baseados em lista invertida.

Navarro e outros~\citep{navarro2000adding}  estudaram uma possível combinação entre índice invertido completo e pesquisa sequencial sem indexação. A pesquisa completa em coleções de texto é feita com o uso de um índice que aponta para blocos em vez de apontar para cada posição no texto. Primeiramente, a pesquisa é realizada no índice para detectar blocos que podem corresponder à consulta e, em seguida, no segundo nível é feita uma pesquisa sequencial para encontrar a lista real de
ocorrências no texto.

Quanto ao índice utilizado no primeiro nível, é possível utilizar índices baseados em árvores \textit{trie}. Heinz et al. \citep{heinz2002burst} propõem a estrutura \textit{Burst Trie}, a qual pode ser considerada como um outro exemplo de índice de dois níveis, porém é aplicada em outro contexto. As \textit{Burst Tries} são coleções de pequenas estruturas de dados denominadas ``recipientes''. Esses ``recipientes'' são análogos ao segundo nível nos moldes explicados anteriormente, e são acessados através de uma \textit{trie} comum, a qual pode ser considerada como um primeiro nível.

Um problema comum a todos os métodos de complementação automática de consultas tolerante a erros supracitados é o alto consumo de memória, uma vez que todos utilizam a estrutura Trie para indexar todo o texto de cada consulta da base de dados. Tendo como influência a combinação de índice invertido e pesquisa sequencial sem indexação (``busca em dois níveis''), uma forma de reduzir a quantidade de memória necessária seria indexar somente alguns caracteres iniciais de cada consulta na árvore Trie, e utilizar de pesquisa sequencial caso o processamento precise ir além das folhas da árvore. 

Costa Xavier \citep{xavier2019} realizou um trabalho preliminar que confirmou a hipótese de que é possível utilizar uma estrutura de busca em dois níveis para o problema de complementação automática de consultas tolerante a erros. Nesse método, define-se uma quantidade fixa $L$ de caracteres (profundidade máxima da Trie), e então somente os $L$ primeiros caracteres de cada consulta são indexados na árvore. Dado um prefixo de consulta $P$ tal que $|P| > L$, a computação de sugestões é dividida em duas etapas, ou níveis. O primeiro nível utiliza o algoritmo ICAN \citep{ji2009efficient} para processar os $L$ primeiros caracteres de $P$. Após o término, resta um conjunto de nós ativos da Trie referentes à sub-cadeia  $P[1..L]$. Então, no segundo nível, é realizada uma busca sequencial em cada consulta referenciada por cada nó ativo. 

Após esse primeiro trabalho, Gama Ferreira \citep{berg2020} aprimorou significativamente a busca em dois níveis ao utilizar utilizar o mesmo algoritmo (BEVA) de busca nos dois níveis da TRIE. Além disso, o trabalho propõem uma estratégia de inserção de chaves em seu índice Trie que acelera o processamento das consultas por utilizar o sistema de cache das máquinas de maneira mais eficiente. Essa mudança na forma de inserir chaves tem potencial para causar melhorias também em outros algoritmos baseados em Trie presentes na literatura. A busca sequencial no segundo nível deste método é mais eficiente que a de \cite{xavier2019}, porque os estados de computação de distância de edição já existentes no primeiro nível podem ser usados para poupar redundâncias computacionais no segundo nível. Tal método atingiu uma ótima economia de memória em comparação ao algoritmo original BEVA, com o aditivo de conseguir manter um desempenho semelhante. 

Os trabalhos de \cite{xavier2019} e \cite{berg2020} demonstraram que é possível combinar a estratégia de busca em índices Trie com busca sequencial para resolver o problema de CATE. Essa combinação permite uma redução significativa do uso de memória necessário, enquanto o tempo de processamento permanece dentro do limite ideal de $100ms$ para a maioria dos casos experimentados. Nesta dissertação, exploramos a possibilidade de realizar otimizações em alguns casos específicos de processamento de consultas em dois níveis visando obter ganhos de desempenho.
